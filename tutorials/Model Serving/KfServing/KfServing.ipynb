{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample for KFServing SDK v1beta1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a sample for KFServing SDK v1beta1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***!!!***\n",
    "\n",
    "***Kfserving depends on azure-storage-blob 2.1.0.***\n",
    "\n",
    "***This will break some of the ydata packages.***\n",
    "\n",
    "***Please check the kfserving from pipelines laboratory.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install azure-storage-blob==2.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferenceServiceName = \"randomforest1\"\n",
    "inFerenceServiceStorageUri = \"gs://pipelines_artifacts/kfserving/sklearn/randomforest\"\n",
    "inputFile = \"https://raw.githubusercontent.com/ydataai/academy/master/tutorials/Model%20Serving/KfServing/input_files/input.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kubernetes import client \n",
    "from kfserving import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define InferenceService"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the inferenceservice basic on the endpoint spec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_version = constants.KFSERVING_GROUP + \"/v1beta1\"\n",
    "namespace = utils.get_default_target_namespace()\n",
    "\n",
    "annotations = {}\n",
    "annotations[\"sidecar.istio.io/inject\"] = \"false\"\n",
    "isvc = V1beta1InferenceService(\n",
    "    api_version=api_version,\n",
    "    kind=constants.KFSERVING_KIND,\n",
    "    metadata=client.V1ObjectMeta(\n",
    "        name=inferenceServiceName, namespace=namespace, annotations=annotations\n",
    "    ),\n",
    "    spec=V1beta1InferenceServiceSpec(\n",
    "        predictor=V1beta1PredictorSpec(\n",
    "            min_replicas=1,\n",
    "            sklearn=V1beta1SKLearnSpec(\n",
    "                # Store your model with the name model.joblib and provide the file location\n",
    "                # to the storage_uri variable\n",
    "                storage_uri=inFerenceServiceStorageUri,\n",
    "            ),\n",
    "        )\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the InferenceService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KFServing = KFServingClient()\n",
    "KFServing.create(isvc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KFServing.wait_isvc_ready(inferenceServiceName, namespace=namespace)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the InferenceService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "response = requests.get(inputFile)\n",
    "data = response.text\n",
    "\n",
    "url = (\n",
    "    \"http://\"\n",
    "    + inferenceServiceName\n",
    "    + \"-predictor-default\"\n",
    "    + \".\"\n",
    "    + namespace\n",
    "    + \".svc.cluster.local/v1/models/\"\n",
    "    + inferenceServiceName\n",
    "    + \":predict\"\n",
    ")\n",
    "\n",
    "print(url)\n",
    "response = requests.post(url, json.dumps(json.loads(data)))\n",
    "\n",
    "print(\"Input: \")\n",
    "print(json.dumps(data))\n",
    "print(\"\\n\")\n",
    "print(\"Output: \")\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete the InferenceService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KFServing.delete(inferenceServiceName, namespace=namespace)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
