{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3c9bf11-14ea-47f7-9991-41cadba5dbe6",
   "metadata": {},
   "source": [
    "# Connectors - Databricks Delta Lake\n",
    "\n",
    "[YData Fabric provides a seamless integration with Databricks Delta Lake](https://ydata.ai/products/fabric), allowing you to connect,\n",
    "query, and manage your data in Delta Lake with ease. This section will guide you through the benefits,\n",
    "setup, and usage of the Databricks' connector within YData Fabric.\n",
    "\n",
    "### Benefits of Integration\n",
    "Integrating YData Fabric with Databricks offers several key benefits:\n",
    "\n",
    "- **Enhanced Data Accessibility:** Seamlessly access and integrate previously siloed data.\n",
    "- **Improved Data Quality:** Use YData Fabric's tools to enhance the quality of your data through data preparation and augmentation.\n",
    "- **Scalability:** Leverage Databricks' robust infrastructure to scale data processing and AI workloads.\n",
    "- **Streamlined Workflows:** Simplify data workflows with connectors and SDKs, reducing manual effort and potential errors.\n",
    "- **Comprehensive Support:** Benefit from extensive documentation and support for both platforms, ensuring smooth integration and operation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d358cb66-0916-4e24-8c3e-9ebbe89c1cbc",
   "metadata": {},
   "source": [
    "### Use a connector already created in the UI\n",
    "On the Fabric home page, navigate to the *\"Connectors\"* menu. Locate the connector you want to use, click the three vertical dots on the right side, and select *\"Use in Lab\"* as shown in the image below.\n",
    "\n",
    "<img src=\"img/delta_lake_use_in_lab.png\" alt=\"Use Databricks Delta Lake connector inside the lab\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72403051-83e4-4586-8839-43ad4d1ea3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing YData's packages\n",
    "from ydata.labs import Connectors\n",
    "# Getting a previously created Connector\n",
    "connector = Connectors.get(uid='insert-connector-uid',\n",
    "                           namespace='insert-namespace-id')\n",
    "print(connector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f76f8b-1a8b-4606-a4c1-9ba90343daa7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Read from your Delta Lake\n",
    "\n",
    "Using the Delta Lake connector it is possible to:\n",
    "- Get the data from a Delta Lake table\n",
    "- Get a sample from a Delta Lake table\n",
    "- Get the data from a query to a Delta Lake instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "275ccdbe-b220-4926-b481-5f871653c764",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: 2024-06-11 22:01:11,445 Successfully opened session 01ef283e-1d15-1af3-98a1-f98419972ba9\n",
      "INFO: 2024-06-11 22:01:12,055 Successfully opened session 01ef283e-1d7e-1f4a-b6fb-a89fe5ff57a8\n",
      "\u001B[1mDataset \n",
      " \n",
      "\u001B[0m\u001B[1mShape: \u001B[0m(5000, 13)\n",
      "\u001B[1mSchema: \u001B[0m\n",
      "         Column Variable type\n",
      "0            id        string\n",
      "1           age           int\n",
      "2        gender           int\n",
      "3        height           int\n",
      "4        weight         float\n",
      "5         ap_hi           int\n",
      "6         ap_lo           int\n",
      "7   cholesterol           int\n",
      "8          gluc           int\n",
      "9         smoke           int\n",
      "10         alco           int\n",
      "11       active           int\n",
      "12       cardio           int\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Define what warehouse you want to use for the activity\n",
    "#This method reads all the data records in the table\n",
    "table = connector.get_table('insert-table-name',\n",
    "                            warehouse='insert-warehouse-name')\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f13e164e-666b-447d-a1e1-51f6c038b9d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1mDataset \n",
      " \n",
      "\u001B[0m\u001B[1mShape: \u001B[0m(50, 13)\n",
      "\u001B[1mSchema: \u001B[0m\n",
      "         Column Variable type\n",
      "0            id        string\n",
      "1           age           int\n",
      "2        gender           int\n",
      "3        height           int\n",
      "4        weight         float\n",
      "5         ap_hi           int\n",
      "6         ap_lo           int\n",
      "7   cholesterol           int\n",
      "8          gluc           int\n",
      "9         smoke           int\n",
      "10         alco           int\n",
      "11       active           int\n",
      "12       cardio           int\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Define what warehouse you want to use for the activity\n",
    "#This method reads a sample with number of records = provided sample size\n",
    "table_sample = connector.get_table_sample(table='insert-table-name',\n",
    "                                          warehouse='insert-warehouse-name',\n",
    "                                          sample_size=50)\n",
    "print(table_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80412745-1df9-4bed-bb18-2cff91dabe91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: 2024-06-11 22:08:56,902 Successfully opened session 01ef283f-328f-115a-a977-2da27926d77a\n",
      "\u001B[1mDataset \n",
      " \n",
      "\u001B[0m\u001B[1mShape: \u001B[0m(5000, 13)\n",
      "\u001B[1mSchema: \u001B[0m\n",
      "         Column Variable type\n",
      "0            id        string\n",
      "1           age           int\n",
      "2        gender           int\n",
      "3        height           int\n",
      "4        weight         float\n",
      "5         ap_hi           int\n",
      "6         ap_lo           int\n",
      "7   cholesterol           int\n",
      "8          gluc           int\n",
      "9         smoke           int\n",
      "10         alco           int\n",
      "11       active           int\n",
      "12       cardio           int\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_output = connector.query(\"SELECT * FROM catalogname.schemaname.tablename;\",\n",
    "                               warehouse='insert-warehouse-name')\n",
    "print(query_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525b263d-032c-473d-a10b-c51e0312e18a",
   "metadata": {},
   "source": [
    "## Write to your Databricks Delta Lake\n",
    "If you need to write your data into a Delta Lake instance you can also leverage your Databricks Delta Lake connector for the following actions:\n",
    "\n",
    "- Write the data into a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa0d8cfc-4146-4332-b205-7d080c374ae1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: 2024-06-11 22:14:05,486 Some parameters are only considered for CSV files: \"sep\", \"has_header\" and \"columns\".\n"
     ]
    }
   ],
   "source": [
    "# Write the data to a new table called cardio_test in the set schema\n",
    "# If exists allow you to decide wether you want to append, replace or fail in case a table with the same name already exists in the schema.\n",
    "connector.write_table(data=query_output,\n",
    "                      staging_path='s3://ydata-dev/regular/internet_sales/test.csv',\n",
    "                      table='cardio_new',\n",
    "                      warehouse='Starter Warehouse',\n",
    "                      if_exists='fail')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
