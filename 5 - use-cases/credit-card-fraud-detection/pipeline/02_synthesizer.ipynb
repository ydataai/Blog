{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae5d4bb4-759c-4d57-bafa-6f4251d10e24",
   "metadata": {},
   "source": [
    "# 2. Training the synthesizer only on the fraudulent events\n",
    "\n",
    "For the process of synthesis we shall only consider the fraudulent data.\n",
    "\n",
    "#### Import the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "788c6b21-ec6e-4d2c-8845-9c6983f7a214",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ave here YData's lib to be called and used in the Jupyter Notebook\n",
    "import os\n",
    "\n",
    "from functions.saving_functions import save_file, read_file\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from ydata.connectors.filetype import FileType\n",
    "\n",
    "from ydata.metadata import Metadata\n",
    "from ydata.dataset import Dataset\n",
    "from ydata.synthesizers.regular import RegularSynthesizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56859109-bdee-4ba4-a16a-20cb17095d7c",
   "metadata": {},
   "source": [
    "#### Getting the environment specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99f71ed5-ae86-476a-b507-f79bb0fd18ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "augment = int(os.getenv(\"AUGMENT\", 0))\n",
    "sample_size = int(os.getenv(\"SAMPLE_SIZE\", 500))\n",
    "output_path = str(os.getenv(\"OUTPUT_PATH\", \"sample.pkl\"))\n",
    "\n",
    "pipeline_settings = {\n",
    "    'sample_size': sample_size,\n",
    "    'augment': augment\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "328b8c32-329e-4b85-819e-d6766ec125a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a43357-1dd1-4bf3-9df5-c39ddbf95716",
   "metadata": {},
   "source": [
    "### Training and sampling for a Synthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb96ecbd-c535-46e9-8872-c18bd11787b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud = read_file('fraud.pkl')\n",
    "if augment==1:\n",
    "    dataset = Dataset(fraud)\n",
    "    metadata = Metadata(dataset)\n",
    "    \n",
    "    fraud_synth = RegularSynthesizer()\n",
    "    fraud_synth.fit(dataset, metadata)\n",
    "    \n",
    "    sample = fraud_synth.sample(sample_size)\n",
    "    \n",
    "    fraud = pd.concat([sample.to_pandas(), fraud], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d47636-57c2-40c2-9634-b67d1de9e04b",
   "metadata": {},
   "source": [
    "### Saving the trained synthesizer\n",
    "For the next steps of the pipeline we need the trained synthesizer to generate synthetic fraudulent samples. To enable the synthesizer for the next pipeline steps, it is required to save it as a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1d827b2-154f-4d61-9b1b-dba554f7af0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file(fraud, output_path)\n",
    "\n",
    "save_file(pipeline_settings, 'pipeline_config.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
